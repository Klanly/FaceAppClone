{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 1. StyleGAN_Encoder_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkycNxEeUWBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf sample_data\n",
        "!git clone https://github.com/pbaylies/stylegan-encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-L8CaC6O6Bv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd stylegan-encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glg1mT2aKizL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOUSJ7TMO6ph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rm -rf aligned_images raw_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5khz8dizO_JB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mkdir aligned_images raw_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU_R54n2_qYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "import io\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "\n",
        "VIDEO_HTML = \"\"\"\n",
        "<video autoplay\n",
        " width=%d height=%d style='cursor: pointer;'></video>\n",
        "<script>\n",
        "\n",
        "var video = document.querySelector('video')\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({ video: true })\n",
        "  .then(stream=> video.srcObject = stream)\n",
        "  \n",
        "var data = new Promise(resolve=>{\n",
        "  video.onclick = ()=>{\n",
        "    var canvas = document.createElement('canvas')\n",
        "    var [w,h] = [video.offsetWidth, video.offsetHeight]\n",
        "    canvas.width = w\n",
        "    canvas.height = h\n",
        "    canvas.getContext('2d')\n",
        "          .drawImage(video, 0, 0, w, h)\n",
        "    video.srcObject.getVideoTracks()[0].stop()\n",
        "    video.replaceWith(canvas)\n",
        "    resolve(canvas.toDataURL('image/jpeg', %f))\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def take_photo(quality=1.0, size=(800,600)):\n",
        "  display(HTML(VIDEO_HTML % (size[0],size[1],quality)))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  f = io.BytesIO(binary)\n",
        "  img = np.asarray(Image.open(f))\n",
        "  \n",
        "  timestampStr = datetime.now().strftime(\"%d-%b-%Y (%H:%M:%S.%f)\")\n",
        "  filename = 'raw_images/photo_%s.jpeg' %timestampStr\n",
        "  Image.fromarray(img).save(filename)\n",
        "  print('Image captured and saved to %s' %filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVBAWK0nMjZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "img = take_photo() # click the image to capture a frame!\n",
        "img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0hakluVJXvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "imgs = sorted(os.listdir('raw_images'))\n",
        "\n",
        "print(\"Found %d images in %s\" %(len(imgs), 'raw_images'))\n",
        "if len(imgs) == 0:\n",
        "  print(\"Upload images to the \\\"raw_images\\\" folder!\")\n",
        "else:\n",
        "  print(imgs)\n",
        "\n",
        "for img_path in imgs:\n",
        "  img = Image.open('raw_images/' + img_path)\n",
        "  \n",
        "  w,h = img.size\n",
        "  rescale_ratio = 256 / min(w,h)\n",
        "  img = img.resize((int(rescale_ratio*w),int(rescale_ratio*h)), Image.LANCZOS)\n",
        "  print(type(img))\n",
        "  display(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de-TddqU_dY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python align_images.py raw_images/ aligned_images/ --output_size=1048"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_Er59x8Mt54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display_folder_content(folder, res = 256):\n",
        "  if folder[-1] != '/': folder += '/'\n",
        "  for i, img_path in enumerate(sorted(os.listdir(folder))):\n",
        "    if '.png' in img_path:\n",
        "      display(Image.open(folder+img_path).resize((res,res)), 'img %d: %s' %(i, img_path))\n",
        "      print('\\n')\n",
        "      \n",
        "display_folder_content('aligned_images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVdh8LIdQVSz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1aT59NFy9-bNyXjDuZOTMl0qX0jmZc6Zb\n",
        "!mkdir data\n",
        "!mv finetuned_resnet.h5 data\n",
        "!rm -rf generated_images latent_representations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1WKZNN3vFVv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"aligned_images contains %d images ready for encoding!\" %len(os.listdir('aligned_images/')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaAu5s2Z5Ag2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python encode_images.py --batch_size=2 --output_video=True --load_resnet='data/finetuned_resnet.h5' --lr=0.01 --decay_rate=0.8 --iterations=200 --use_l1_penalty=0.3 aligned_images/ generated_images/ latent_representations/\n",
        "print(\"\\n************ Latent code optimization finished! ***************\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-ErZhh9cqUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dnnlib, pickle\n",
        "import dnnlib.tflib as tflib\n",
        "tflib.init_tf()\n",
        "synthesis_kwargs = dict(output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True), minibatch_size=1)\n",
        "\n",
        "model_dir = 'cache/'\n",
        "model_path = [model_dir+f for f in os.listdir(model_dir) if 'stylegan-ffhq' in f][0]\n",
        "print(\"Loading StyleGAN model from %s...\" %model_path)\n",
        "\n",
        "with dnnlib.util.open_url(model_path) as f:\n",
        "  generator_network, discriminator_network, averaged_generator_network = pickle.load(f)\n",
        "  \n",
        "print(\"StyleGAN loaded & ready for sampling!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9argInqrgIji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_images(generator, latent_vector, z = True):\n",
        "    batch_size = latent_vector.shape[0]\n",
        "    \n",
        "    if z: #Start from z: run the full generator network\n",
        "        return generator.run(latent_vector.reshape((batch_size, 512)), None, randomize_noise=False, **synthesis_kwargs)\n",
        "    else: #Start from w: skip the mapping network\n",
        "        return generator.components.synthesis.run(latent_vector.reshape((batch_size, 18, 512)), randomize_noise=False, **synthesis_kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaSENEp8efOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "def plot_imgs(model, rows, columns):\n",
        "  for i in range(rows):\n",
        "    f, axarr = plt.subplots(1,columns, figsize = (20,8))\n",
        "    for j in range(columns):\n",
        "      img = generate_images(model, np.random.randn(1,512), z = True)[0]\n",
        "      axarr[j].imshow(img)\n",
        "      axarr[j].axis('off')\n",
        "      axarr[j].set_title('Resolution: %s' %str(img.shape))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwwHDl-heh6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_imgs(averaged_generator_network, 3, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHRNwnSshG_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "for f in sorted(os.listdir('latent_representations')):\n",
        "  w = np.load('latent_representations/' + f).reshape((1,18,-1))\n",
        "  img = generate_images(averaged_generator_network, w, z = False)[0]\n",
        "  plt.imshow(img)\n",
        "  plt.axis('off')\n",
        "  plt.title(\"Generated image from %s\" %f)\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab7zzXNuJMzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_two_images(img1,img2, img_id, fs = 12):\n",
        "  f, axarr = plt.subplots(1,2, figsize=(fs,fs))\n",
        "  axarr[0].imshow(img1)\n",
        "  axarr[0].title.set_text('Encoded img %d' %img_id)\n",
        "  axarr[1].imshow(img2)\n",
        "  axarr[1].title.set_text('Original img %d' %img_id)\n",
        "  plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
        "  plt.show()\n",
        "\n",
        "def display_sbs(folder1, folder2, res = 256):\n",
        "  if folder1[-1] != '/': folder1 += '/'\n",
        "  if folder2[-1] != '/': folder2 += '/'\n",
        "    \n",
        "  imgs1 = sorted([f for f in os.listdir(folder1) if '.png' in f])\n",
        "  imgs2 = sorted([f for f in os.listdir(folder2) if '.png' in f])\n",
        "  if len(imgs1)!=len(imgs2):\n",
        "    print(\"Found different amount of images in aligned vs raw image directories. That's not supposed to happen...\")\n",
        "  \n",
        "  for i in range(len(imgs1)):\n",
        "    img1 = Image.open(folder1+imgs1[i]).resize((res,res))\n",
        "    img2 = Image.open(folder2+imgs2[i]).resize((res,res))\n",
        "    plot_two_images(img1,img2, i)\n",
        "    print(\"\")\n",
        "     \n",
        "display_sbs('generated_images/', 'aligned_images/', res = 512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBifaaJ3PKq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "good_images = [0]  #Change these numbers to pick out latents that worked well (see the image plots)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGj-xKoYX1TZ",
        "colab_type": "text"
      },
      "source": [
        "## Save these latent vectors to disk:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKtgwRDPOgrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "latents = sorted(os.listdir('latent_representations'))\n",
        "latents\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwnONbCLkzLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_file = '/content/output_vectors.npy'\n",
        "\n",
        "final_w_vectors = []\n",
        "for img_id in good_images:\n",
        "  w = np.load('latent_representations/' + latents[img_id])\n",
        "  final_w_vectors.append(w)\n",
        "\n",
        "final_w_vectors = np.array(final_w_vectors)\n",
        "np.save(out_file, final_w_vectors)\n",
        "print(\"%d latent vectors of shape %s saved to %s!\" %(len(good_images), str(w.shape), out_file))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S3pYlKISjxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}